input {
  file {
    path => "FILE_PATH"
  }
}

filter {
  grok {
    match => ["message" , "%{BASE10NUM:start_time_unixtimestamp_dot_ms}\t%{IP:cs_ip}\t%{WORD:cs_method}\t%{USER:ssl_version}\t%{NOTSPACE:cs_uri}\t%{BASE10NUM:sc_status}\t%{BASE10NUM:sc_content_bytes}\t%{BASE10NUM:sc_total_bytes}\t%{BASE10NUM:s_object_size}\t(?:%{BASE10NUM:s_uncompressed_size}|-)\t(?:%{BASE10NUM:http_overhead_bytes}|-)\t%{QS:cs_referrer}\t%{QS:cs_user_agent}\t%{QS:cs_cookie}\t%{QS:cs_host}\t%{QS:sc_content_type}\t(?:%{BASE10NUM:x_time_ssloverhead_ms}|-)\t(?:%{BASE10NUM:x_time_turnaround_ms}|-)\t(?:%{BASE10NUM:x_time_transfer_ms}|-)\t%{QS:x_request_id}\t(?:%{BASE10NUM:x_max_age}|-)\t%{QS:x_cache_status}\t%{QS:x_cache_refresh_source}\t(?:%{BASE10NUM:x_last_byte_served_flag}|-)\t(?:%{BASE10NUM:x_no_store_flag}|-)"]
  }
  if "_grokparsefailure" in [tags] {
    drop { }
  }
  date {
    match => ["start_time_unixtimestamp_dot_ms", "UNIX"]
  }
  geoip {
    source => "cs_ip"
  }
  mutate {
    convert => {
      "x_time_turnaround_ms" => "float"
      "x_time_transfer_ms" => "float"
      "sc_total_bytes" => "float"
      "x_max_age" => "float"
      "sc_content_bytes" => "float"
      "s_uncompressed_size" => "float"
    }
  }
}

output {
  elasticsearch {
    host => ELASTICSEARCH_NODES
    index => "logstash-akamai-%{+YYYY.MM.dd}"
  }
}
